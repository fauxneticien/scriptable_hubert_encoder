{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "485517c5-92c8-4960-b4cb-485f85862339",
   "metadata": {},
   "source": [
    "# Try `torch.compile` on A100 machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ffd187-63dc-474e-9805-6621bc7763d1",
   "metadata": {},
   "source": [
    "Use a machine with a `torch.compile`-compatible/-recommended GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da3868ab-8589-42e8-b312-8f104c79b973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Sep  7 22:15:26 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-PCI...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   27C    P0    32W / 250W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d96a426-c314-4d28-a53c-56c33a892902",
   "metadata": {},
   "source": [
    "## Get some data to pass through model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72715367-6c38-412b-a1a1-d21d7a19dfa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feats_padded': tensor([[[ 8.0312,  6.3081,  5.6085,  ...,  9.9287,  9.7825,  9.2193],\n",
       "          [ 6.0623,  5.5936,  6.3717,  ...,  8.7658,  9.4892,  9.5833],\n",
       "          [ 6.5774,  5.4523,  7.3200,  ...,  9.1725,  9.9851,  9.9644],\n",
       "          ...,\n",
       "          [ 6.8111,  6.4719,  7.3717,  ..., 11.5423, 11.6784, 11.2297],\n",
       "          [ 6.3828,  7.6254,  8.7734,  ..., 15.8933, 16.1830, 16.0805],\n",
       "          [ 7.8642,  7.3241,  8.9053,  ..., 11.0786, 10.8585, 10.8489]],\n",
       " \n",
       "         [[ 8.3438,  7.9204,  7.6191,  ...,  9.3661,  9.0802,  8.9283],\n",
       "          [ 8.0286,  6.6956,  8.4073,  ...,  9.4909,  9.6967,  8.9417],\n",
       "          [ 8.9658,  9.1295,  8.5936,  ...,  9.2658,  9.3963,  9.5405],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[ 8.1562,  6.2256,  5.9716,  ...,  9.9072,  9.6092,  9.2015],\n",
       "          [ 8.8425,  8.7941,  7.7824,  ...,  9.5978,  9.5073,  9.4639],\n",
       "          [ 9.0547,  8.6465,  7.6734,  ...,  8.6344,  9.6870,  9.5321],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]),\n",
       " 'feat_lens': tensor([756, 750, 748], dtype=torch.int32),\n",
       " 'ptlabels_padded': tensor([[ 240,   50,   50,  ...,  266,   79,  166],\n",
       "         [ 240,   50,  420,  ..., -100, -100, -100],\n",
       "         [ 240,   50,  420,  ..., -100, -100, -100]]),\n",
       " 'ptlabels_lengths': tensor([756, 750, 748], dtype=torch.int32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from lhotse import CutSet\n",
    "\n",
    "from lhotse.dataset import DynamicBucketingSampler\n",
    "from lhotse.dataset.collation import collate_custom_field\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "train_data_dir = Path('data/mini-librispeech/train-clean-5')\n",
    "\n",
    "train_cuts = CutSet.from_shar(fields={\n",
    "    'cuts': sorted(list(train_data_dir.glob(\"cuts.*.jsonl.gz\"))),\n",
    "    'fbank': sorted(list(train_data_dir.glob(\"fbank.*.tar\"))),\n",
    "    'ptlabel': sorted(list(train_data_dir.glob(\"ptlabel.*.tar\")))\n",
    "})\n",
    "\n",
    "train_sampler = DynamicBucketingSampler(\n",
    "    train_cuts,\n",
    "    # Dynamically sample items that\n",
    "    # altogther add up to 60 seconds\n",
    "    max_duration=60\n",
    "  )\n",
    "\n",
    "class HuBERTPretrainingDataset(Dataset):\n",
    "    def __getitem__(self, cuts: CutSet) -> dict:\n",
    "        cuts = cuts.sort_by_duration()\n",
    "\n",
    "        # Collate and pad\n",
    "        feats_padded, feat_lens = collate_custom_field(cuts, 'fbank', pad_value=0)\n",
    "        # Note we'll use a negative integer for padding the labels since 0 is a valid label\n",
    "        ptlabels_padded, ptlabels_lengths = collate_custom_field(cuts, 'ptlabel', pad_value=-100)\n",
    "\n",
    "        return {\"feats_padded\": feats_padded, \"feat_lens\": feat_lens, \"ptlabels_padded\": ptlabels_padded, \"ptlabels_lengths\": ptlabels_lengths}\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    HuBERTPretrainingDataset(),\n",
    "    sampler=train_sampler,\n",
    "    batch_size=None,\n",
    "    num_workers=1\n",
    ")\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2284e56-069b-4163-8c80-cd726ae8b49a",
   "metadata": {},
   "source": [
    "## Pre-process data for forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "481b8b52-e682-4e70-b9c2-dcd5a795db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from components.verbatim_torchaudio import _get_padding_mask, _compute_mask_indices\n",
    "\n",
    "padding_mask = _get_padding_mask(batch['feats_padded'], batch['feat_lens'])\n",
    "\n",
    "B, T, C = batch['feats_padded'].shape\n",
    "\n",
    "masks_for_modeling = _compute_mask_indices(\n",
    "    (B, T),\n",
    "    padding_mask,\n",
    "    # Use HuBERT defaults\n",
    "    mask_prob=0.8,\n",
    "    mask_length=10,\n",
    "    mask_type='static',\n",
    "    mask_other=0.0,\n",
    "    min_masks=2,\n",
    "    no_overlap=False,\n",
    "    min_space=1,\n",
    ")\n",
    "\n",
    "# Zero-out random frames\n",
    "batch['feats_padded'][masks_for_modeling] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebf6703-fcf5-4137-a53c-244530ff945c",
   "metadata": {},
   "source": [
    "## Construct and compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eab02cd1-8083-4b15-8b7e-320e46e66810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): Encoder(\n",
       "    (feature_projection): FeatureProjection(\n",
       "      (layer_norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=80, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (pos_conv_embed): ConvolutionalPositionalEmbedding(\n",
       "        (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x EncoderLayer(\n",
       "          (attention): SelfAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): FeedForward(\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from components.model import get_torchaudio_hubert_pretrain_base_encoder\n",
    "\n",
    "model = get_torchaudio_hubert_pretrain_base_encoder()\n",
    "\n",
    "opt_model = torch.compile(model)\n",
    "\n",
    "opt_model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf83bab0-aa44-490d-9b6a-4169d1089fcd",
   "metadata": {},
   "source": [
    "It compiled! Will it work right out of the box?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58869784-1dcf-437b-a277-2c77cd5c69a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-09-07 22:29:11,055] torch._inductor.graph: [ERROR] Error from lowering\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/graph.py\", line 333, in call_function\n",
      "    out = lowerings[target](*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py\", line 225, in wrapped\n",
      "    out = decomp_fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py\", line 2020, in index_put\n",
      "    return index_put_(clone(x), indices, values, accumulate)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py\", line 225, in wrapped\n",
      "    out = decomp_fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py\", line 2044, in index_put_\n",
      "    return index_put_as_masked_fill(self, indices, values, accumulate)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py\", line 2028, in index_put_as_masked_fill\n",
      "    return mutate_to(self, where(indices[0], value, self))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py\", line 225, in wrapped\n",
      "    out = decomp_fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py\", line 454, in where\n",
      "    for i, x in zip(indices, broadcast_tensors(*[args[i] for i in indices])):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py\", line 225, in wrapped\n",
      "    out = decomp_fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py\", line 468, in broadcast_tensors\n",
      "    target = functools.reduce(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py\", line 280, in broadcast_symbolic_shapes\n",
      "    V.graph.sizevars.guard_equals(a, b)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/_inductor/sizevars.py\", line 253, in guard_equals\n",
      "    assert self.shape_env.evaluate_expr(sympy.Eq(left, right))\n",
      "AssertionError\n"
     ]
    },
    {
     "ename": "BackendCompilerFailed",
     "evalue": "debug_wrapper raised LoweringException: AssertionError: \n  target: aten.index_put.default\n  args[0]: TensorBox(StorageBox(\n    Pointwise(\n      'cuda',\n      torch.float32,\n      tmp0 = load(seed_cuda_0, 0)\n      tmp1 = index_expr(i2 + 768 * i1 + 580608 * i0, torch.int32)\n      tmp2 = rand(tmp0, tmp1, torch.float32)\n      tmp3 = constant(0.1, torch.float32)\n      tmp4 = tmp2 > tmp3\n      tmp5 = to_dtype(tmp4, torch.float32)\n      tmp6 = load(buf6, i2 + 768 * i1 + 580608 * i0)\n      tmp7 = tmp5 * tmp6\n      tmp8 = constant(1.1111111111111112, torch.float32)\n      tmp9 = tmp7 * tmp8\n      return tmp9\n      ,\n      ranges=[3, 756, 768],\n      origins={convert_element_type, mul_2, primals_3, mul_3, primals_4, view, gt, philox_rand_like, permute, view_1, philox_seed_like, addmm}\n    )\n  ))\n  args[1]: [TensorBox(StorageBox(\n    ComputedBuffer(name='buf7', layout=FixedLayout('cuda', torch.bool, size=[3, 756], stride=[756, 1]), data=Pointwise(\n      'cuda',\n      torch.bool,\n      tmp0 = index_expr(i1, dtype=torch.int64)\n      tmp1 = load(primals_6, i0)\n      tmp2 = tmp0 >= tmp1\n      return tmp2\n      ,\n      ranges=[3, 756],\n      origins={ge}\n    ))\n  ))]\n  args[2]: TensorBox(StorageBox(\n    Pointwise(\n      'cpu',\n      torch.float32,\n      tmp0 = constant(0.0, torch.float32)\n      return tmp0\n      ,\n      ranges=[],\n      origins={lift_fresh_copy, _tensor_constant0}\n    )\n  ))\n\nWhile executing %index_put : [#users=1] = call_function[target=torch.ops.aten.index_put.default](args = (%mul_3, [%ge], %lift_fresh_copy), kwargs = {})\nOriginal traceback:\n  File \"/home/scriptable_hubert_encoder/components/verbatim_torchaudio.py\", line 254, in _preprocess\n    x[mask] = 0.0\n |   File \"/home/scriptable_hubert_encoder/components/verbatim_torchaudio.py\", line 265, in forward\n    x, mask = self._preprocess(features, lengths)\n\n\nSet torch._dynamo.config.verbose=True for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    torch._dynamo.config.suppress_errors = True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/graph.py:333\u001b[0m, in \u001b[0;36mGraphLowering.call_function\u001b[0;34m(self, target, args, kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mlowerings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py:225\u001b[0m, in \u001b[0;36m_register_lowering.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m             args[i] \u001b[38;5;241m=\u001b[39m ExpandView\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    222\u001b[0m                 args[i], \u001b[38;5;28mlist\u001b[39m(args[indices[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mget_size())\n\u001b[1;32m    223\u001b[0m             )\n\u001b[0;32m--> 225\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mdecomp_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m validate_ir(out)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py:2020\u001b[0m, in \u001b[0;36mindex_put\u001b[0;34m(x, indices, values, accumulate)\u001b[0m\n\u001b[1;32m   2018\u001b[0m \u001b[38;5;129m@register_lowering\u001b[39m([aten\u001b[38;5;241m.\u001b[39mindex_put])\n\u001b[1;32m   2019\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindex_put\u001b[39m(x, indices, values, accumulate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2020\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindex_put_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py:225\u001b[0m, in \u001b[0;36m_register_lowering.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m             args[i] \u001b[38;5;241m=\u001b[39m ExpandView\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    222\u001b[0m                 args[i], \u001b[38;5;28mlist\u001b[39m(args[indices[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mget_size())\n\u001b[1;32m    223\u001b[0m             )\n\u001b[0;32m--> 225\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mdecomp_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m validate_ir(out)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py:2044\u001b[0m, in \u001b[0;36mindex_put_\u001b[0;34m(self, indices, values, accumulate)\u001b[0m\n\u001b[1;32m   2039\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2040\u001b[0m     values\u001b[38;5;241m.\u001b[39mget_numel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2041\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indices) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2042\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m indices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_dtype() \u001b[38;5;129;01min\u001b[39;00m {torch\u001b[38;5;241m.\u001b[39mbool, torch\u001b[38;5;241m.\u001b[39muint8}\n\u001b[1;32m   2043\u001b[0m ):\n\u001b[0;32m-> 2044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindex_put_as_masked_fill\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2046\u001b[0m \u001b[38;5;66;03m# Fallback if there is a boolean index\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py:2028\u001b[0m, in \u001b[0;36mindex_put_as_masked_fill\u001b[0;34m(self, indices, value, accumulate)\u001b[0m\n\u001b[1;32m   2027\u001b[0m     value \u001b[38;5;241m=\u001b[39m add(\u001b[38;5;28mself\u001b[39m, value)\n\u001b[0;32m-> 2028\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mutate_to(\u001b[38;5;28mself\u001b[39m, \u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py:225\u001b[0m, in \u001b[0;36m_register_lowering.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m             args[i] \u001b[38;5;241m=\u001b[39m ExpandView\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    222\u001b[0m                 args[i], \u001b[38;5;28mlist\u001b[39m(args[indices[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mget_size())\n\u001b[1;32m    223\u001b[0m             )\n\u001b[0;32m--> 225\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mdecomp_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m validate_ir(out)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py:454\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(cond, a, b)\u001b[0m\n\u001b[1;32m    453\u001b[0m indices \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(args) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, TensorBox)]\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(indices, \u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    455\u001b[0m     args[i] \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py:225\u001b[0m, in \u001b[0;36m_register_lowering.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m             args[i] \u001b[38;5;241m=\u001b[39m ExpandView\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    222\u001b[0m                 args[i], \u001b[38;5;28mlist\u001b[39m(args[indices[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mget_size())\n\u001b[1;32m    223\u001b[0m             )\n\u001b[0;32m--> 225\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mdecomp_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m validate_ir(out)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py:468\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*inputs)\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m broadcast_tensors(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 468\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbroadcast_symbolic_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m outputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/lowering.py:280\u001b[0m, in \u001b[0;36mbroadcast_symbolic_shapes\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 280\u001b[0m     \u001b[43mV\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msizevars\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguard_equals\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sympy\u001b[38;5;241m.\u001b[39mexpand(b)\u001b[38;5;241m.\u001b[39mfree_symbols) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(sympy\u001b[38;5;241m.\u001b[39mexpand(a)\u001b[38;5;241m.\u001b[39mfree_symbols):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/sizevars.py:253\u001b[0m, in \u001b[0;36mSizeVarAllocator.guard_equals\u001b[0;34m(self, left, right)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mguard_equals\u001b[39m(\u001b[38;5;28mself\u001b[39m, left: Expr, right: Expr) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Expr:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_env\u001b[38;5;241m.\u001b[39mevaluate_expr(sympy\u001b[38;5;241m.\u001b[39mEq(left, right))\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m left\n",
      "\u001b[0;31mAssertionError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mLoweringException\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:670\u001b[0m, in \u001b[0;36mOutputGraph.call_user_compiler\u001b[0;34m(self, gm)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfake_example_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    671\u001b[0m _step_logger()(logging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone compiler function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py:1055\u001b[0m, in \u001b[0;36mwrap_backend_debug.<locals>.debug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1055\u001b[0m     compiled_gm \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_gm\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/__init__.py:1390\u001b[0m, in \u001b[0;36m_TorchCompileInductorWrapper.__call__\u001b[0;34m(self, model_, inputs_)\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_inductor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompile_fx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compile_fx\n\u001b[0;32m-> 1390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompile_fx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_patches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:455\u001b[0m, in \u001b[0;36mcompile_fx\u001b[0;34m(model_, example_inputs_, inner_compile, config_patches)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m overrides\u001b[38;5;241m.\u001b[39mpatch_functions():\n\u001b[1;32m    451\u001b[0m \n\u001b[1;32m    452\u001b[0m     \u001b[38;5;66;03m# TODO: can add logging before/after the call to create_aot_dispatcher_function\u001b[39;00m\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;66;03m# in torch._functorch/aot_autograd.py::aot_module_simplified::aot_function_simplified::new_func\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m# once torchdynamo is merged into pytorch\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43maot_autograd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfw_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbw_compiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbw_compiler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecompositions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselect_decomp_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartition_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmin_cut_rematerialization_partition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minductor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_inference_input_mutations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs_\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/backends/common.py:48\u001b[0m, in \u001b[0;36maot_autograd.<locals>.compiler_fn\u001b[0;34m(gm, example_inputs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m enable_aot_logging():\n\u001b[0;32m---> 48\u001b[0m     cg \u001b[38;5;241m=\u001b[39m \u001b[43maot_module_simplified\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maot_autograd\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:2822\u001b[0m, in \u001b[0;36maot_module_simplified\u001b[0;34m(mod, args, fw_compiler, bw_compiler, partition_fn, decompositions, hasher_type, static_argnums, keep_inference_input_mutations)\u001b[0m\n\u001b[1;32m   2820\u001b[0m full_args\u001b[38;5;241m.\u001b[39mextend(args)\n\u001b[0;32m-> 2822\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_aot_dispatcher_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunctional_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2824\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfull_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2825\u001b[0m \u001b[43m    \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2826\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2828\u001b[0m \u001b[38;5;66;03m# TODO: There is something deeply wrong here; compiled_fn running with\u001b[39;00m\n\u001b[1;32m   2829\u001b[0m \u001b[38;5;66;03m# the boxed calling convention, but aot_module_simplified somehow\u001b[39;00m\n\u001b[1;32m   2830\u001b[0m \u001b[38;5;66;03m# historically returned a function that was not the boxed calling\u001b[39;00m\n\u001b[1;32m   2831\u001b[0m \u001b[38;5;66;03m# convention.  This should get fixed...\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/utils.py:163\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 163\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:2515\u001b[0m, in \u001b[0;36mcreate_aot_dispatcher_function\u001b[0;34m(flat_fn, flat_args, aot_config)\u001b[0m\n\u001b[1;32m   2513\u001b[0m \u001b[38;5;66;03m# You can put more passes here\u001b[39;00m\n\u001b[0;32m-> 2515\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(compiled_fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_boxed_call\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:1715\u001b[0m, in \u001b[0;36maot_wrapper_dedupe\u001b[0;34m(flat_fn, flat_args, aot_config, compiler_fn)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ok:\n\u001b[0;32m-> 1715\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleaf_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maot_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1717\u001b[0m \u001b[38;5;66;03m# Strategy 2: Duplicate specialize.\u001b[39;00m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;66;03m# In Haskell types, suppose you have:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m#   }\u001b[39;00m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;66;03m#   keep_arg_mask = [True, True, False, True]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py:2150\u001b[0m, in \u001b[0;36maot_dispatch_autograd\u001b[0;34m(flat_fn, flat_args, aot_config)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m track_graph_compiling(aot_config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2150\u001b[0m         compiled_fw_func \u001b[38;5;241m=\u001b[39m \u001b[43maot_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfw_compiler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2151\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfw_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args_with_views_handled\u001b[49m\n\u001b[1;32m   2152\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCompiledFunction\u001b[39;00m(torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mFunction):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/utils.py:163\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 163\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:430\u001b[0m, in \u001b[0;36mcompile_fx.<locals>.fw_compiler\u001b[0;34m(model, example_inputs)\u001b[0m\n\u001b[1;32m    429\u001b[0m model \u001b[38;5;241m=\u001b[39m convert_outplace_to_inplace(model)\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_fixed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcudagraphs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcudagraphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgraph_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/debug_utils.py:595\u001b[0m, in \u001b[0;36mwrap_compiler_debug.<locals>.debug_wrapper\u001b[0;34m(gm, example_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 595\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[43mcompiler_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/debug.py:239\u001b[0m, in \u001b[0;36mDebugContext.wrap.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DebugContext():\n\u001b[0;32m--> 239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:176\u001b[0m, in \u001b[0;36mcompile_fx_inner\u001b[0;34m(gm, example_inputs, cudagraphs, num_fixed, is_backward, graph_id)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m V\u001b[38;5;241m.\u001b[39mset_graph_handler(graph):\n\u001b[0;32m--> 176\u001b[0m     \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexample_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mcompile_to_fn()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/utils.py:163\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 163\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/graph.py:194\u001b[0m, in \u001b[0;36mGraphLowering.run\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;129m@dynamo_timed\u001b[39m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/fx/interpreter.py:136\u001b[0m, in \u001b[0;36mInterpreter.run\u001b[0;34m(self, initial_env, enable_io_processing, *args)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv[node] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/graph.py:407\u001b[0m, in \u001b[0;36mGraphLowering.run_node\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 407\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;66;03m# require the same stride order for dense outputs,\u001b[39;00m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# 1. user-land view() will not throw because inductor\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# output different strides than eager\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# 2: as_strided ops, we need make sure its input has same size/stride with\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;66;03m# eager model to align with eager behavior.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/fx/interpreter.py:177\u001b[0m, in \u001b[0;36mInterpreter.run_node\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(kwargs, \u001b[38;5;28mdict\u001b[39m)\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_inductor/graph.py:337\u001b[0m, in \u001b[0;36mGraphLowering.call_function\u001b[0;34m(self, target, args, kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m log\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError from lowering\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 337\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m LoweringException(e, target, args, kwargs) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mLoweringException\u001b[0m: AssertionError: \n  target: aten.index_put.default\n  args[0]: TensorBox(StorageBox(\n    Pointwise(\n      'cuda',\n      torch.float32,\n      tmp0 = load(seed_cuda_0, 0)\n      tmp1 = index_expr(i2 + 768 * i1 + 580608 * i0, torch.int32)\n      tmp2 = rand(tmp0, tmp1, torch.float32)\n      tmp3 = constant(0.1, torch.float32)\n      tmp4 = tmp2 > tmp3\n      tmp5 = to_dtype(tmp4, torch.float32)\n      tmp6 = load(buf6, i2 + 768 * i1 + 580608 * i0)\n      tmp7 = tmp5 * tmp6\n      tmp8 = constant(1.1111111111111112, torch.float32)\n      tmp9 = tmp7 * tmp8\n      return tmp9\n      ,\n      ranges=[3, 756, 768],\n      origins={convert_element_type, mul_2, primals_3, mul_3, primals_4, view, gt, philox_rand_like, permute, view_1, philox_seed_like, addmm}\n    )\n  ))\n  args[1]: [TensorBox(StorageBox(\n    ComputedBuffer(name='buf7', layout=FixedLayout('cuda', torch.bool, size=[3, 756], stride=[756, 1]), data=Pointwise(\n      'cuda',\n      torch.bool,\n      tmp0 = index_expr(i1, dtype=torch.int64)\n      tmp1 = load(primals_6, i0)\n      tmp2 = tmp0 >= tmp1\n      return tmp2\n      ,\n      ranges=[3, 756],\n      origins={ge}\n    ))\n  ))]\n  args[2]: TensorBox(StorageBox(\n    Pointwise(\n      'cpu',\n      torch.float32,\n      tmp0 = constant(0.0, torch.float32)\n      return tmp0\n      ,\n      ranges=[],\n      origins={lift_fresh_copy, _tensor_constant0}\n    )\n  ))\n\nWhile executing %index_put : [#users=1] = call_function[target=torch.ops.aten.index_put.default](args = (%mul_3, [%ge], %lift_fresh_copy), kwargs = {})\nOriginal traceback:\n  File \"/home/scriptable_hubert_encoder/components/verbatim_torchaudio.py\", line 254, in _preprocess\n    x[mask] = 0.0\n |   File \"/home/scriptable_hubert_encoder/components/verbatim_torchaudio.py\", line 265, in forward\n    x, mask = self._preprocess(features, lengths)\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mBackendCompilerFailed\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mopt_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeats_padded\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeat_lens\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:82\u001b[0m, in \u001b[0;36mOptimizedModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamo_ctx\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_orig_mod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:209\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m dynamic_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:337\u001b[0m, in \u001b[0;36mcatch_errors_wrapper.<locals>.catch_errors\u001b[0;34m(frame, cache_size)\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m hijacked_callback(frame, cache_size, hooks)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m compile_lock:\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:404\u001b[0m, in \u001b[0;36mconvert_frame.<locals>._convert_frame\u001b[0;34m(frame, cache_size, hooks)\u001b[0m\n\u001b[1;32m    402\u001b[0m counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43minner_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframes\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:104\u001b[0m, in \u001b[0;36mwrap_convert_context.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m torch\u001b[38;5;241m.\u001b[39mfx\u001b[38;5;241m.\u001b[39mgraph_module\u001b[38;5;241m.\u001b[39m_forward_from_src \u001b[38;5;241m=\u001b[39m fx_forward_from_src_skip_result\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_set_grad_enabled(prior_grad_mode)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:262\u001b[0m, in \u001b[0;36mconvert_frame_assert.<locals>._convert_frame_assert\u001b[0;34m(frame, cache_size, hooks)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m initial_grad_state\n\u001b[1;32m    260\u001b[0m initial_grad_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_globals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_locals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_builtins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiler_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mone_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/utils.py:163\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     compilation_metrics[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    162\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 163\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:324\u001b[0m, in \u001b[0;36m_compile\u001b[0;34m(code, globals, locals, builtins, compiler_fn, one_graph, export, hooks, frame)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mcount():\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 324\u001b[0m         out_code \u001b[38;5;241m=\u001b[39m \u001b[43mtransform_code_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m         orig_code_map[out_code] \u001b[38;5;241m=\u001b[39m code\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/bytecode_transformation.py:445\u001b[0m, in \u001b[0;36mtransform_code_object\u001b[0;34m(code, transformations, safe)\u001b[0m\n\u001b[1;32m    442\u001b[0m instructions \u001b[38;5;241m=\u001b[39m cleaned_instructions(code, safe)\n\u001b[1;32m    443\u001b[0m propagate_line_nums(instructions)\n\u001b[0;32m--> 445\u001b[0m \u001b[43mtransformations\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m clean_and_assemble_instructions(instructions, keys, code_options)[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py:311\u001b[0m, in \u001b[0;36m_compile.<locals>.transform\u001b[0;34m(instructions, code_options)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mnonlocal\u001b[39;00m output\n\u001b[1;32m    299\u001b[0m tracer \u001b[38;5;241m=\u001b[39m InstructionTranslator(\n\u001b[1;32m    300\u001b[0m     instructions,\n\u001b[1;32m    301\u001b[0m     code,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    309\u001b[0m     mutated_closure_cell_contents,\n\u001b[1;32m    310\u001b[0m )\n\u001b[0;32m--> 311\u001b[0m \u001b[43mtracer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m output \u001b[38;5;241m=\u001b[39m tracer\u001b[38;5;241m.\u001b[39moutput\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:1726\u001b[0m, in \u001b[0;36mInstructionTranslator.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1725\u001b[0m     _step_logger()(logging\u001b[38;5;241m.\u001b[39mINFO, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorchdynamo start tracing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_code\u001b[38;5;241m.\u001b[39mco_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1726\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:576\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mpush_tx(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m (\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstruction_pointer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39mshould_exit\n\u001b[0;32m--> 576\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m     ):\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:540\u001b[0m, in \u001b[0;36mInstructionTranslatorBase.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, inst\u001b[38;5;241m.\u001b[39mopname):\n\u001b[1;32m    539\u001b[0m         unimplemented(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minst\u001b[38;5;241m.\u001b[39mopname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 540\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43minst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inst\u001b[38;5;241m.\u001b[39mopname \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRETURN_VALUE\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BackendCompilerFailed:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/symbolic_convert.py:372\u001b[0m, in \u001b[0;36mbreak_graph_if_unsupported.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m    370\u001b[0m     reason \u001b[38;5;241m=\u001b[39m GraphCompileReason(excp\u001b[38;5;241m.\u001b[39mmsg, user_stack)\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestore_graphstate(state)\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_subgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreason\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreason\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopn(push \u001b[38;5;241m-\u001b[39m dis\u001b[38;5;241m.\u001b[39mstack_effect(inst\u001b[38;5;241m.\u001b[39mopcode, inst\u001b[38;5;241m.\u001b[39marg))\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(push):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:541\u001b[0m, in \u001b[0;36mOutputGraph.compile_subgraph\u001b[0;34m(self, tx, partial_convert, reason)\u001b[0m\n\u001b[1;32m    538\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count_calls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pass2\u001b[38;5;241m.\u001b[39mgraph_outputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    540\u001b[0m     output\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m--> 541\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_and_call_fx_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_output_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m     )\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pass2\u001b[38;5;241m.\u001b[39mgraph_outputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    545\u001b[0m         output\u001b[38;5;241m.\u001b[39mappend(pass2\u001b[38;5;241m.\u001b[39mcreate_store(graph_output_var))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:588\u001b[0m, in \u001b[0;36mOutputGraph.compile_and_call_fx_graph\u001b[0;34m(self, tx, rv, root)\u001b[0m\n\u001b[1;32m    586\u001b[0m assert_no_fake_params_or_buffers(gm)\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tracing(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracing_context):\n\u001b[0;32m--> 588\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_user_compiler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m compiled_fn \u001b[38;5;241m=\u001b[39m disable(compiled_fn)\n\u001b[1;32m    591\u001b[0m counters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstats\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munique_graphs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/utils.py:163\u001b[0m, in \u001b[0;36mdynamo_timed.<locals>.dynamo_timed_inner.<locals>.time_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m     compilation_metrics[key] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    162\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 163\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m time_spent \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# print(f\"Dynamo timer: key={key}, latency={latency:.2f} sec\")\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_dynamo/output_graph.py:675\u001b[0m, in \u001b[0;36mOutputGraph.call_user_compiler\u001b[0;34m(self, gm)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    674\u001b[0m     compiled_fn \u001b[38;5;241m=\u001b[39m gm\u001b[38;5;241m.\u001b[39mforward\n\u001b[0;32m--> 675\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BackendCompilerFailed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompiler_fn, e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_fn\n",
      "\u001b[0;31mBackendCompilerFailed\u001b[0m: debug_wrapper raised LoweringException: AssertionError: \n  target: aten.index_put.default\n  args[0]: TensorBox(StorageBox(\n    Pointwise(\n      'cuda',\n      torch.float32,\n      tmp0 = load(seed_cuda_0, 0)\n      tmp1 = index_expr(i2 + 768 * i1 + 580608 * i0, torch.int32)\n      tmp2 = rand(tmp0, tmp1, torch.float32)\n      tmp3 = constant(0.1, torch.float32)\n      tmp4 = tmp2 > tmp3\n      tmp5 = to_dtype(tmp4, torch.float32)\n      tmp6 = load(buf6, i2 + 768 * i1 + 580608 * i0)\n      tmp7 = tmp5 * tmp6\n      tmp8 = constant(1.1111111111111112, torch.float32)\n      tmp9 = tmp7 * tmp8\n      return tmp9\n      ,\n      ranges=[3, 756, 768],\n      origins={convert_element_type, mul_2, primals_3, mul_3, primals_4, view, gt, philox_rand_like, permute, view_1, philox_seed_like, addmm}\n    )\n  ))\n  args[1]: [TensorBox(StorageBox(\n    ComputedBuffer(name='buf7', layout=FixedLayout('cuda', torch.bool, size=[3, 756], stride=[756, 1]), data=Pointwise(\n      'cuda',\n      torch.bool,\n      tmp0 = index_expr(i1, dtype=torch.int64)\n      tmp1 = load(primals_6, i0)\n      tmp2 = tmp0 >= tmp1\n      return tmp2\n      ,\n      ranges=[3, 756],\n      origins={ge}\n    ))\n  ))]\n  args[2]: TensorBox(StorageBox(\n    Pointwise(\n      'cpu',\n      torch.float32,\n      tmp0 = constant(0.0, torch.float32)\n      return tmp0\n      ,\n      ranges=[],\n      origins={lift_fresh_copy, _tensor_constant0}\n    )\n  ))\n\nWhile executing %index_put : [#users=1] = call_function[target=torch.ops.aten.index_put.default](args = (%mul_3, [%ge], %lift_fresh_copy), kwargs = {})\nOriginal traceback:\n  File \"/home/scriptable_hubert_encoder/components/verbatim_torchaudio.py\", line 254, in _preprocess\n    x[mask] = 0.0\n |   File \"/home/scriptable_hubert_encoder/components/verbatim_torchaudio.py\", line 265, in forward\n    x, mask = self._preprocess(features, lengths)\n\n\nSet torch._dynamo.config.verbose=True for more information\n\n\nYou can suppress this exception and fall back to eager by setting:\n    torch._dynamo.config.suppress_errors = True\n"
     ]
    }
   ],
   "source": [
    "transformer_outputs = opt_model(\n",
    "    batch['feats_padded'].to('cuda'),\n",
    "    batch['feat_lens'].to('cuda')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79edc833-0111-4629-bc81-a3cf7742498d",
   "metadata": {},
   "source": [
    "Alright, I guess while `torch.compile()` didn't complain, still too good to be true to work right out of the gate. Seems the error is related to `self._preprocess(features, lengths)`\n",
    "\n",
    "```\n",
    "Original traceback:\n",
    "  File \"/home/scriptable_hubert_encoder/components/verbatim_torchaudio.py\", line 254, in _preprocess\n",
    "    x[mask] = 0.0\n",
    " |   File \"/home/scriptable_hubert_encoder/components/verbatim_torchaudio.py\", line 265, in forward\n",
    "    x, mask = self._preprocess(features, lengths)\n",
    "\n",
    "\n",
    "Set torch._dynamo.config.verbose=True for more information\n",
    "```\n",
    "\n",
    "Seems it does not like the attention mask calculation being inside the `_preprocess` function:\n",
    "\n",
    "```\n",
    "def _preprocess(\n",
    "    self,\n",
    "    features: Tensor,\n",
    "    lengths: Optional[Tensor] = None,\n",
    ") -> Tuple[Tensor, Optional[Tensor]]:\n",
    "    x = self.feature_projection(features)\n",
    "\n",
    "    mask: Optional[Tensor] = None\n",
    "    if lengths is not None:\n",
    "        batch_size, max_len, _ = x.shape\n",
    "        # create mask for padded elements and zero-out them\n",
    "        mask = torch.arange(max_len, device=lengths.device).expand(batch_size, max_len) >= lengths[:, None]\n",
    "        x[mask] = 0.0\n",
    "        # extend the mask to attention shape and set weight\n",
    "        mask = -10000.0 * mask[:, None, None, :].to(dtype=features.dtype)\n",
    "        mask = mask.expand(batch_size, 1, max_len, max_len)\n",
    "    return x, mask\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86284d-2448-44e0-a2a8-7ae0bbede52d",
   "metadata": {},
   "source": [
    "## Calculate post-projection attention mask outside of compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7563d10-96bf-4ee2-b538-1717ba54c859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): FeatureProjection(\n",
       "    (layer_norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)\n",
       "    (projection): Linear(in_features=80, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_feat_proj = torch.compile(model.feature_projection).to('cuda')\n",
    "\n",
    "opt_feat_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "911581dd-a256-48bc-8e9d-7e45ad0c74a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = opt_feat_proj(batch['feats_padded'].to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0a76aeaa-15fa-4bab-a6d6-6581b040f5b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Output 0 of CompiledFunctionBackward is a view and is being modified inplace. This view was created inside a custom Function (or because an input was returned as-is) and the autograd logic to handle view+inplace would override the custom backward associated with the custom Function, leading to incorrect gradients. This behavior is forbidden. You can fix this by cloning the output of the custom Function.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# create mask for padded elements and zero-out them\u001b[39;00m\n\u001b[1;32m      5\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(max_len, device\u001b[38;5;241m=\u001b[39mlengths\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mexpand(batch_size, max_len) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m lengths[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m----> 6\u001b[0m x[mask] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# extend the mask to attention shape and set weight\u001b[39;00m\n\u001b[1;32m      8\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10000.0\u001b[39m \u001b[38;5;241m*\u001b[39m mask[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Output 0 of CompiledFunctionBackward is a view and is being modified inplace. This view was created inside a custom Function (or because an input was returned as-is) and the autograd logic to handle view+inplace would override the custom backward associated with the custom Function, leading to incorrect gradients. This behavior is forbidden. You can fix this by cloning the output of the custom Function."
     ]
    }
   ],
   "source": [
    "lengths = batch['feat_lens']\n",
    "\n",
    "batch_size, max_len, _ = x.shape\n",
    "# create mask for padded elements and zero-out them\n",
    "mask = torch.arange(max_len, device=lengths.device).expand(batch_size, max_len) >= lengths[:, None]\n",
    "x[mask] = 0.0\n",
    "# extend the mask to attention shape and set weight\n",
    "mask = -10000.0 * mask[:, None, None, :].to(dtype=features.dtype)\n",
    "mask = mask.expand(batch_size, 1, max_len, max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64997e2-2e41-4f35-a49c-303c4bebaaa0",
   "metadata": {},
   "source": [
    "Hm why does `x[mask] = 0.0` need to be set? Isn't the point of the `mask`/`attention_mask` to prevent the transformer from paying attention to these positions?\n",
    "\n",
    "Anyway comment this out and continue with a not-zeroed-out `x` to see if the rest of the forward pass will work with `torch.compile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8ac11927-7788-4a01-8d46-b176ad2d48bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[    -0.,     -0.,     -0.,  ...,     -0.,     -0.,     -0.],\n",
       "          [    -0.,     -0.,     -0.,  ...,     -0.,     -0.,     -0.],\n",
       "          [    -0.,     -0.,     -0.,  ...,     -0.,     -0.,     -0.],\n",
       "          ...,\n",
       "          [    -0.,     -0.,     -0.,  ...,     -0.,     -0.,     -0.],\n",
       "          [    -0.,     -0.,     -0.,  ...,     -0.,     -0.,     -0.],\n",
       "          [    -0.,     -0.,     -0.,  ...,     -0.,     -0.,     -0.]]],\n",
       "\n",
       "\n",
       "        [[[    -0.,     -0.,     -0.,  ..., -10000., -10000., -10000.],\n",
       "          [    -0.,     -0.,     -0.,  ..., -10000., -10000., -10000.],\n",
       "          [    -0.,     -0.,     -0.,  ..., -10000., -10000., -10000.],\n",
       "          ...,\n",
       "          [    -0.,     -0.,     -0.,  ..., -10000., -10000., -10000.],\n",
       "          [    -0.,     -0.,     -0.,  ..., -10000., -10000., -10000.],\n",
       "          [    -0.,     -0.,     -0.,  ..., -10000., -10000., -10000.]]],\n",
       "\n",
       "\n",
       "        [[[    -0.,     -0.,     -0.,  ..., -10000., -10000., -10000.],\n",
       "          [    -0.,     -0.,     -0.,  ..., -10000., -10000., -10000.],\n",
       "          [    -0.,     -0.,     -0.,  ..., -10000., -10000., -10000.],\n",
       "          ...,\n",
       "          [    -0.,     -0.,     -0.,  ..., -10000., -10000., -10000.],\n",
       "          [    -0.,     -0.,     -0.,  ..., -10000., -10000., -10000.],\n",
       "          [    -0.,     -0.,     -0.,  ..., -10000., -10000., -10000.]]]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = batch['feat_lens']\n",
    "\n",
    "batch_size, max_len, _ = x.shape\n",
    "# create mask for padded elements and zero-out them\n",
    "mask = torch.arange(max_len, device=lengths.device).expand(batch_size, max_len) >= lengths[:, None]\n",
    "# x[mask] = 0.0\n",
    "# extend the mask to attention shape and set weight\n",
    "mask = -10000.0 * mask[:, None, None, :].to(dtype=batch[\"feats_padded\"].dtype)\n",
    "mask = mask.expand(batch_size, 1, max_len, max_len)\n",
    "\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97aca97f-2a1e-4ee0-83d1-41e47fbdadb3",
   "metadata": {},
   "source": [
    "## Pass (projected) features and attention mask to transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1f202a12-c865-4722-8e4a-a978ebe92a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OptimizedModule(\n",
       "  (_orig_mod): Transformer(\n",
       "    (pos_conv_embed): ConvolutionalPositionalEmbedding(\n",
       "      (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x EncoderLayer(\n",
       "        (attention): SelfAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): FeedForward(\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_transformer = torch.compile(model.transformer).to('cuda')\n",
    "\n",
    "opt_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abc54ebc-85ec-465b-97ff-b29f1e8ba366",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = opt_transformer(x, attention_mask=mask.to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b9d19c1-aae5-43fd-a2e6-2d914ec7570a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.5501e-01,  9.0716e-01,  4.5373e-01,  ..., -1.1112e-01,\n",
       "          -3.5967e-01,  2.7984e-01],\n",
       "         [-1.6776e+00, -8.4338e-01,  5.5379e-01,  ...,  1.3777e+00,\n",
       "          -6.9165e-01, -4.6057e-01],\n",
       "         [-1.5607e-01, -3.0129e-01,  4.0043e-01,  ...,  1.5154e+00,\n",
       "           6.7790e-02, -3.2070e-01],\n",
       "         ...,\n",
       "         [ 2.8277e-01, -3.5982e-01,  2.8334e-01,  ...,  3.9271e-01,\n",
       "          -3.2856e-01, -1.6475e+00],\n",
       "         [-2.1042e-01, -7.6817e-01,  8.8457e-01,  ..., -2.5041e-01,\n",
       "           3.4465e-01, -1.1508e+00],\n",
       "         [-1.2911e-01, -4.2044e-01,  8.6431e-01,  ...,  1.9125e+00,\n",
       "           7.7329e-02, -9.6082e-01]],\n",
       "\n",
       "        [[-6.7865e-01, -1.0606e+00,  2.3368e-01,  ...,  9.5067e-01,\n",
       "           4.8681e-01, -1.8798e-01],\n",
       "         [ 6.8016e-01, -1.0107e+00, -8.2733e-01,  ...,  9.6873e-02,\n",
       "           5.3239e-01, -2.2120e+00],\n",
       "         [-7.2662e-01, -8.6442e-02,  9.7579e-01,  ...,  7.6153e-01,\n",
       "          -2.8874e-01,  8.8322e-02],\n",
       "         ...,\n",
       "         [ 3.2440e-01, -5.6570e-01, -1.0120e+00,  ...,  2.1364e-01,\n",
       "          -1.4812e+00, -7.1868e-01],\n",
       "         [ 4.5275e-01, -3.6771e-01, -5.7000e-01,  ..., -3.4653e-01,\n",
       "          -1.0702e+00, -1.1494e+00],\n",
       "         [-1.6428e+00, -8.9357e-04,  1.1537e+00,  ..., -1.2882e+00,\n",
       "          -6.2942e-01, -1.1904e+00]],\n",
       "\n",
       "        [[-6.2188e-01, -6.8105e-01, -1.0661e+00,  ...,  1.8426e+00,\n",
       "          -1.4476e-01, -4.0684e-01],\n",
       "         [-9.3865e-01, -6.6254e-01,  4.2439e-01,  ..., -8.9849e-01,\n",
       "           1.4472e+00, -9.7440e-01],\n",
       "         [-2.9719e-01, -2.9523e-01, -1.8335e-01,  ...,  1.6802e+00,\n",
       "           5.3793e-01, -1.7358e-02],\n",
       "         ...,\n",
       "         [ 8.2881e-01,  6.7062e-01,  7.4059e-01,  ...,  2.9355e-01,\n",
       "          -1.9278e+00,  1.8796e-01],\n",
       "         [-5.9160e-01,  3.8441e-01,  1.0392e+00,  ...,  7.5072e-01,\n",
       "          -6.7317e-01,  9.3593e-01],\n",
       "         [-1.3908e+00,  2.0492e+00,  1.0640e+00,  ..., -6.2688e-01,\n",
       "          -9.2558e-01,  1.5762e+00]]], device='cuda:0',\n",
       "       grad_fn=<CompiledFunctionBackward>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6e58f2-747c-4010-9598-1c1fb02fe1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
